{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from statistics import mode\n",
    "%run Utilities.ipynb\n",
    "%run Preprocessor.ipynb\n",
    "%run LineSegmentor.ipynb\n",
    "%run FeatureExtractor.ipynb\n",
    "%run FeatureExtractor2.ipynb\n",
    "%run Classifiers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#Path to generate the dataset at\n",
    "testDatasetDirectory = \"Data\\\\data\\\\\"\n",
    "\n",
    "prep = Preprocessor()\n",
    "extractor=LBP_Feature_Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(x_test)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|████████████▎                                                                    | 91/600 [07:41<40:50,  4.82s/it]D:\\Anaconda\\envs\\pattern\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 23%|██████████████████▌                                                             | 139/600 [11:45<40:08,  5.22s/it]D:\\Anaconda\\envs\\pattern\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      " 89%|███████████████████████████████████████████████████████████████████████▎        | 535/600 [48:22<05:32,  5.12s/it]D:\\Anaconda\\envs\\pattern\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [54:21<00:00,  5.44s/it]\n"
     ]
    }
   ],
   "source": [
    "SVMcounter = 0\n",
    "KNNcounter = 0\n",
    "RandomForest8counter = 0\n",
    "NNcounter = 0\n",
    "counter = 0\n",
    "SlantCounter = 0\n",
    "for i in tqdm(range(0,600)):\n",
    "    \n",
    "    ##################################TRAINING############################################################\n",
    "    ######Reading the inputs and labelling the training dataset######\n",
    "    \n",
    "    z = '%02d' % i\n",
    "    #z = '32'\n",
    "    \n",
    "#     if not os.path.exists(testDatasetDirectory+z):\n",
    "#         continue\n",
    "    x_train, y_train, x_test = readTestCase(testDatasetDirectory+z)\n",
    "    x_train_gray = []\n",
    "    x_train_binary = []\n",
    "    x_train_original = []\n",
    "\n",
    "    \n",
    "    #####Preprocessing every image in the input dataset######\n",
    "    for img in x_train:    \n",
    "        gray, binary, original = prep.preprocessing_pipeline_image(img)\n",
    "        x_train_gray.append(gray)\n",
    "        x_train_binary.append(binary)\n",
    "        x_train_original.append(original)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    x_train_segments =  np.empty(256)\n",
    "    y_train_segments = []\n",
    "\n",
    "    for i in range(len(x_train_gray)):\n",
    "        gray_lines, binary_lines, orig_lines = LineSegmentor(x_train_gray[i], x_train_binary[i], x_train_original[i]).segment()\n",
    "        \n",
    "        for j in range(len(binary_lines)):\n",
    "#             if j>4:\n",
    "#                 break\n",
    "            lbpHist = computeLBPHist(binary_lines[j])\n",
    "            x_train_segments = np.vstack((x_train_segments, lbpHist))\n",
    "            \n",
    "            ##Labelling the segmented dataset##\n",
    "            if (i<2):\n",
    "                y_train_segments.append(1)\n",
    "            elif (i<4):\n",
    "                y_train_segments.append(2)\n",
    "            else:\n",
    "                y_train_segments.append(3) \n",
    "    \n",
    "    \n",
    "    y_train_segments = np.asarray(y_train_segments)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ######################################TEST###################################################### \n",
    "    \n",
    "    #####Preprocessing every image in the testing dataset######\n",
    "    x_test_gray, x_test_binary, x_test_original = prep.preprocessing_pipeline_image(x_test)\n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    ####And Calculating the features vector####\n",
    "    gray_lines, binary_lines, orig_lines = LineSegmentor(x_test_gray, x_test_binary, x_test_original).segment()\n",
    "    x_test_segments = np.empty([len(binary_lines), 256])\n",
    "    \n",
    "    \n",
    "    for i in range(len(binary_lines)):\n",
    "        lbpHist = computeLBPHist(binary_lines[i])\n",
    "        x_test_segments[i] = lbpHist\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####Classifying the test case#####\n",
    "    SVMResults = SVMClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    KNNResults = KNNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    RandomForest8Results = RandForestClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, max_depth=8, random_state=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    results = SVMResults\n",
    "    results = np.vstack((results,KNNResults))\n",
    "    results = np.vstack((results,RandomForest8Results))\n",
    "    results = np.sum(results, axis = 0)\n",
    "    \n",
    "    \n",
    "    if results[np.argmax(results)]/(sum(results)*100) < 60:\n",
    "            NNResults = NNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, hidden_layer_sizes = [100, 50])\n",
    "            results = np.vstack((results,NNResults))\n",
    "     \n",
    "    results = np.sum(results, axis = 0)\n",
    "    prediction = np.zeros(1)\n",
    "    prediction[0] = np.argmax(results) + 1\n",
    "    \n",
    "    if isCorrect(testDatasetDirectory, z, prediction):  \n",
    "        counter += 1\n",
    "#    else:\n",
    "#         print(results)\n",
    "#         print(z)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590\n"
     ]
    }
   ],
   "source": [
    "# print(SVMcounter)\n",
    "# print(KNNcounter)\n",
    "# print(KNN5counter)\n",
    "# print(KMeanscounter)\n",
    "# print(RandomForest2counter)\n",
    "# print(RandomForest4counter)\n",
    "# print(RandomForest6counter)\n",
    "# print(RandomForest8counter)\n",
    "# print(RandomForest10counter)\n",
    "#print(SlantCounter)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98.33333333333333\n"
     ]
    }
   ],
   "source": [
    "print((counter/600)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
