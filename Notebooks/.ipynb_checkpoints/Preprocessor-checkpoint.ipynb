{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always make all imports in the first cell of the notebook, run them all once.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import skimage\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.filters.rank import otsu\n",
    "from skimage.filters import median, threshold_otsu\n",
    "# import import_ipynb\n",
    "# import Utilities\n",
    "%run Utilities.ipynb\n",
    "%run LineSegmentor.ipynb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    @staticmethod\n",
    "    def read_images(fileName, imagesIDs):\n",
    "        #fileName = fileName + '/*png'\n",
    "        x_train = []\n",
    "        x_images_names = []\n",
    "        for imageID in imagesIDs:\n",
    "            img = cv2.imread(fileName+'/'+imageID) ## cv2.imread reads images in RGB format\n",
    "            x_images_names.append(imageID)\n",
    "            x_train.append(img)\n",
    "        x_train = np.asarray(x_train)\n",
    "        return x_train, x_images_names\n",
    "        \n",
    "    @staticmethod    \n",
    "    def preprocess(img):\n",
    "        # Reduce image noise.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "\n",
    "        # Binarize the image.\n",
    "        # _,thresholded_img =  cv2.threshold(img, 165,255,cv2.THRESH_BINARY)\n",
    "        _,thresholded_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Return pre processed images.\n",
    "        return thresholded_img\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def crop(img, origImg):\n",
    "        # Converting the image to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        \n",
    "        # Finding all contours in the image\n",
    "        contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "\n",
    "        # Minimum contour width to be considered as the black separator line.\n",
    "        threshold_width = 1000\n",
    "        line_offset = 0\n",
    "        \n",
    "        \n",
    "        # Page paragraph boundaries.\n",
    "        height, width = gray.shape\n",
    "        up, down, left, right = 0, height - 1, 0, width - 1\n",
    "\n",
    "        # Detect the main horizontal black separator lines of the IAM handwriting forms.\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w < threshold_width:\n",
    "                continue\n",
    "            if y < height // 2:\n",
    "                up = max(up, y + h + line_offset)\n",
    "            else:\n",
    "                down = min(down, y - line_offset)\n",
    "   \n",
    "        # Applying filters to enhance the image    \n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        eroded_img = cv2.erode(binary, kernel, iterations=2)\n",
    "        # Get horizontal and vertical histograms.\n",
    "        hor_hist = np.sum(eroded_img, axis=1) / 255\n",
    "        ver_hist = np.sum(eroded_img, axis=0) / 255\n",
    "\n",
    "        # Detect paragraph white padding.\n",
    "        while left < right and ver_hist[left] == 0:\n",
    "            left += 1\n",
    "        while right > left and ver_hist[right] == 0:\n",
    "            right -= 1\n",
    "        while up < down and hor_hist[up] == 0:\n",
    "            up += 1\n",
    "        while down > up and hor_hist[down] == 0:\n",
    "            down -= 1\n",
    "            \n",
    "        gray = gray[up:down + 1, left:right + 1]\n",
    "        binary = binary[up:down + 1, left:right + 1]\n",
    "        origImg = origImg[up:down + 1, left:right + 1]\n",
    "    \n",
    "\n",
    "        return gray, binary, origImg\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_preprocessed(fileName, x_images_names, x_train_gray,x_train_binary, x_train_orig, writer_id):\n",
    "        gray_directory='PreprocessedImages/'+writer_id+'/gray/'\n",
    "        binary_directory='PreprocessedImages/'+writer_id+'/binary/'\n",
    "        orig_directory='PreprocessedImages/'+writer_id+'/orig/'\n",
    "        if not os.path.exists(fileName +gray_directory):\n",
    "            os.makedirs(fileName +gray_directory)\n",
    "        if not os.path.exists(fileName +binary_directory):\n",
    "            os.makedirs(fileName +binary_directory)\n",
    "        if not os.path.exists(fileName +orig_directory):\n",
    "            os.makedirs(fileName +orig_directory)     \n",
    "#        for i in range(len(x_train_gray)):\n",
    "#             print(fileName +'gray/' + str(x_images_names[i]))\n",
    "#             print(fileName + 'binary/' + str(x_images_names[i]))\n",
    "#             cv2.imwrite(fileName +gray_directory + str(x_images_names[i]) ,x_train_gray[i])\n",
    "#             cv2.imwrite(fileName + binary_directory + str(x_images_names[i]),x_train_binary[i])\n",
    "#             cv2.imwrite(fileName + orig_directory + str(x_images_names[i]),x_train_orig[i])\n",
    "\n",
    "    @staticmethod\n",
    "    def preprocessing_pipeline(fileName, imagesIDs,writer_id):\n",
    "        x_train, x_images_names = Preprocessor.read_images(fileName, imagesIDs)\n",
    "        x_train_gray = []\n",
    "        x_train_binary = []\n",
    "        x_train_orig = []\n",
    "        for origImg in x_train:\n",
    "            preprocessedImage = Preprocessor.preprocess(origImg)\n",
    "            croppedImageGray, croppedImageBinary, croppedImageOriginal = Preprocessor.crop(preprocessedImage, origImg)\n",
    "            x_train_gray.append(croppedImageGray)\n",
    "            x_train_binary.append(croppedImageBinary)\n",
    "            x_train_orig.append(croppedImageOriginal)\n",
    "        \n",
    "        \n",
    "        Preprocessor.save_preprocessed(fileName, x_images_names, x_train_gray, x_train_binary,x_train_orig,writer_id)\n",
    "        return x_train_gray, x_train_binary, x_train_orig \n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocessing_pipeline_image(image):\n",
    " \n",
    "        preprocessedImage = Preprocessor.preprocess(image)\n",
    "        croppedImageGray, croppedImageBinary, croppedImageOriginal = Preprocessor.crop(preprocessedImage, image)\n",
    "        return croppedImageGray, croppedImageBinary, croppedImageOriginal \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_writers_images_names(file_path):\n",
    "#     try:\n",
    "#         file = open(file_path, \"r\")\n",
    "#         file_lines = file.readlines()\n",
    "#         for i in range(len(file_lines)):\n",
    "#             file_lines[i] = file_lines[i].rstrip(\"\\n\")\n",
    "#         file.close()\n",
    "#         return file_lines\n",
    "#     except IOError:\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "013\n",
      "['a01-053.png', 'a01-058.png', 'a01-063.png']\n"
     ]
    }
   ],
   "source": [
    "# prep = Preprocessor()\n",
    "# z = '%03d' % 13\n",
    "# writerImagesID = get_writers_images_names(\"Data\\Writers\\\\\"+z+\".txt\")\n",
    "# print(z)\n",
    "# print(writerImagesID)\n",
    "# x_train_gray, x_train_binary, x_train_orig = prep.preprocessing_pipeline('Data/AllDataset',writerImagesID,z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gray_segments, bin_segments, orig_segments = segment_writer('Data/AllDatasetPreprocessedImages/', '013')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
