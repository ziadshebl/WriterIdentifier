{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from statistics import mode\n",
    "%run Utilities.ipynb\n",
    "%run Preprocessor.ipynb\n",
    "%run LineSegmentor.ipynb\n",
    "%run FeatureExtractor.ipynb\n",
    "%run FeatureExtractor2.ipynb\n",
    "%run Classifiers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#Path to generate the dataset at\n",
    "testDatasetDirectory = \"Data\\\\data\\\\\"\n",
    "\n",
    "prep = Preprocessor()\n",
    "extractor=LBP_Feature_Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(x_test)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|████████████████████████▉                                                          | 3/10 [00:31<01:13, 10.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.43738408 23.37887353  4.18374239]\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|█████████████████████████████████▏                                                 | 4/10 [00:42<01:03, 10.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.94218314 21.03138806  4.02642881]\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████████████████████████████████████████████████████████                         | 7/10 [01:11<00:29,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17.41123839 19.71763822  2.87112339]\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|██████████████████████████████████████████████████████████████████████████▋        | 9/10 [01:31<00:09,  9.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11.58064714 20.38629652  8.03305634]\n",
      "89\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 10/10 [01:41<00:00, 10.10s/it]\n"
     ]
    }
   ],
   "source": [
    "SVMcounter = 0\n",
    "KNNcounter = 0\n",
    "RandomForest8counter = 0\n",
    "NNcounter = 0\n",
    "counter = 0\n",
    "SlantCounter = 0\n",
    "for i in tqdm(range(0,10)):\n",
    "    \n",
    "    ##################################TRAINING############################################################\n",
    "    ######Reading the inputs and labelling the training dataset######\n",
    "    \n",
    "    #z = '%02d' % i\n",
    "    z = '89'\n",
    "    \n",
    "#     if not os.path.exists(testDatasetDirectory+z):\n",
    "#         continue\n",
    "    x_train, y_train, x_test = readTestCase(testDatasetDirectory+z)\n",
    "    x_train_gray = []\n",
    "    x_train_binary = []\n",
    "    x_train_original = []\n",
    "\n",
    "    \n",
    "    #####Preprocessing every image in the input dataset######\n",
    "    for img in x_train:    \n",
    "        gray, binary, original = prep.preprocessing_pipeline_image(img)\n",
    "        x_train_gray.append(gray)\n",
    "        x_train_binary.append(binary)\n",
    "        x_train_original.append(original)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    x_train_segments =  np.empty(256)\n",
    "    y_train_segments = []\n",
    "\n",
    "    for i in range(len(x_train_gray)):\n",
    "        gray_lines, binary_lines, orig_lines = LineSegmentor(x_train_gray[i], x_train_binary[i], x_train_original[i]).segment()\n",
    "        \n",
    "        for j in range(len(binary_lines)):\n",
    "            lbpHist = computeLBPHist(binary_lines[j])\n",
    "            x_train_segments = np.vstack((x_train_segments, lbpHist))\n",
    "            \n",
    "            ##Labelling the segmented dataset##\n",
    "            if (i<2):\n",
    "                y_train_segments.append(1)\n",
    "            elif (i<4):\n",
    "                y_train_segments.append(2)\n",
    "            else:\n",
    "                y_train_segments.append(3) \n",
    "    \n",
    "    \n",
    "    y_train_segments = np.asarray(y_train_segments)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ######################################TEST###################################################### \n",
    "    \n",
    "    #####Preprocessing every image in the testing dataset######\n",
    "    x_test_gray, x_test_binary, x_test_original = prep.preprocessing_pipeline_image(x_test)\n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    ####And Calculating the features vector####\n",
    "    gray_lines, binary_lines, orig_lines = LineSegmentor(x_test_gray, x_test_binary, x_test_original).segment()\n",
    "    x_test_segments = np.empty([len(binary_lines), 256])\n",
    "    \n",
    "    \n",
    "    for i in range(len(binary_lines)):\n",
    "        lbpHist = computeLBPHist(binary_lines[i])\n",
    "        x_test_segments[i] = lbpHist\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####Classifying the test case#####\n",
    "    SVMResults = SVMClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    KNNResults = KNNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    " \n",
    "    \n",
    "    results = SVMResults\n",
    "    results = np.vstack((results,KNNResults))\n",
    "    results = np.sum(results, axis = 0)\n",
    "    \n",
    "    \n",
    "    if results[np.argmax(results)]/(sum(results)*100) < 60:\n",
    "        NNResults = NNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, random_state = random.seed(120), hidden_layer_sizes = [75, 35], max_iter = 500,)\n",
    "        results = np.vstack((results,NNResults))\n",
    "\n",
    "        XGBoostResults = XGBoost(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, max_depth=6, random_state=random.seed(120), learning_rate = 1,  n_estimators=300) \n",
    "        results = np.vstack((results,XGBoostResults))\n",
    "        results = np.sum(results, axis = 0)\n",
    "     \n",
    "        \n",
    "    \n",
    "    \n",
    "    prediction = np.zeros(1)\n",
    "    prediction[0] = np.argmax(results) + 1\n",
    "    \n",
    "    if isCorrect(testDatasetDirectory, z, prediction):  \n",
    "        counter += 1\n",
    "    else:\n",
    "        print(results)\n",
    "        print(z)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
