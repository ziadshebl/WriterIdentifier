{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from statistics import mode\n",
    "%run Utilities.ipynb\n",
    "%run Preprocessor.ipynb\n",
    "%run LineSegmentor.ipynb\n",
    "%run FeatureExtractor.ipynb\n",
    "%run FeatureExtractor2.ipynb\n",
    "%run Classifiers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#Path to generate the dataset at\n",
    "testDatasetDirectory = \"Data\\data\\\\\"\n",
    "\n",
    "prep = Preprocessor()\n",
    "extractor=LBP_Feature_Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(x_test)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█████████████▏                                                                   | 65/400 [06:55<35:52,  6.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|█████████████████████████████████▏                                              | 166/400 [18:35<25:54,  6.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|███████████████████████████████████████████▏                                    | 216/400 [24:44<23:52,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████████████████████████████████████████████▊                                  | 229/400 [26:24<23:05,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|███████████████████████████████████████████████████████▏                        | 276/400 [32:12<14:42,  7.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|██████████████████████████████████████████████████████████▌                     | 293/400 [34:12<12:23,  6.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|██████████████████████████████████████████████████████████████▌                 | 313/400 [36:33<09:32,  6.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|█████████████████████████████████████████████████████████████████▊              | 329/400 [38:27<08:02,  6.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|█████████████████████████████████████████████████████████████████████▏          | 346/400 [40:34<06:55,  7.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████████████████████████████████████████████████████████████████████▏       | 361/400 [42:15<04:21,  6.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|████████████████████████████████████████████████████████████████████████▊       | 364/400 [42:34<03:53,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|███████████████████████████████████████████████████████████████████████████▊    | 379/400 [44:18<02:21,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|███████████████████████████████████████████████████████████████████████████████▍| 397/400 [46:20<00:19,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 400/400 [46:39<00:00,  7.00s/it]\n"
     ]
    }
   ],
   "source": [
    "SVMcounter = 0\n",
    "KNNcounter = 0\n",
    "KNN5counter = 0\n",
    "KMeanscounter = 0\n",
    "RandomForest2counter = 0\n",
    "RandomForest4counter = 0\n",
    "RandomForest6counter = 0\n",
    "RandomForest8counter = 0\n",
    "RandomForest10counter = 0\n",
    "counter = 0\n",
    "for i in tqdm(range(400)):\n",
    "    \n",
    "    ##################################TRAINING############################################################\n",
    "    ######Reading the inputs and labelling the training dataset######\n",
    "    z = '%02d' % i\n",
    "    #z = '01'\n",
    "    x_train, y_train, x_test = readTestCase(testDatasetDirectory+z)\n",
    "    x_train_gray = []\n",
    "    x_train_binary = []\n",
    "    x_train_original = []\n",
    "\n",
    "    \n",
    "    #####Preprocessing every image in the input dataset######\n",
    "    for img in x_train:    \n",
    "        gray, binary, original = prep.preprocessing_pipeline_image(img)\n",
    "        x_train_gray.append(gray)\n",
    "        x_train_binary.append(binary)\n",
    "        x_train_original.append(original)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    x_train_segments =  np.empty(256)\n",
    "    y_train_segments = []\n",
    "\n",
    "    for i in range(len(x_train)):\n",
    "        gray_lines, binary_lines, orig_lines = LineSegmentor(x_train_gray[i], x_train_binary[i], x_train_original[i]).segment()\n",
    "        \n",
    "        for j in range(len(binary_lines)):\n",
    "#             if j>4:\n",
    "#                 break\n",
    "            lbpHist = computeLBPHist(binary_lines[j])\n",
    "            x_train_segments = np.vstack((x_train_segments, lbpHist))\n",
    "            \n",
    "            ##Labelling the segmented dataset##\n",
    "            if (i<2):\n",
    "                y_train_segments.append(1)\n",
    "            elif (i<4):\n",
    "                y_train_segments.append(2)\n",
    "            else:\n",
    "                y_train_segments.append(3) \n",
    "    \n",
    "    \n",
    "    y_train_segments = np.asarray(y_train_segments)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ######################################TEST###################################################### \n",
    "    \n",
    "    #####Preprocessing every image in the testing dataset######\n",
    "    x_test_gray, x_test_binary, x_test_original = prep.preprocessing_pipeline_image(x_test)\n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    ####And Calculating the features vector####\n",
    "    gray_lines, binary_lines, orig_lines = LineSegmentor(x_test_gray, x_test_binary, x_test_original).segment()\n",
    "    x_test_segments = np.empty([len(binary_lines), 256])\n",
    "    \n",
    "    \n",
    "    for i in range(len(binary_lines)):\n",
    "        lbpHist = computeLBPHist(binary_lines[i])\n",
    "        x_test_segments[i] = lbpHist\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####Classifying the test case#####\n",
    "    SVMResults = SVMClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    KNNResults = KNNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    RandomForest8Results = RandForestClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, max_depth=8, random_state=0)\n",
    "\n",
    "    results = SVMResults\n",
    "    results = np.vstack((results,KNNResults))\n",
    "    results = np.vstack((results,RandomForest8Results))\n",
    "    results =  np.sum(results, axis = 0)\n",
    "    \n",
    "    prediction = np.zeros(1)\n",
    "    prediction[0] = np.argmax(results) + 1\n",
    "    \n",
    "    if isCorrect(testDatasetDirectory, z, prediction):  \n",
    "        counter += 1\n",
    "    else:\n",
    "        print(z)\n",
    "        \n",
    "        \n",
    "    ####Calculating Accuracy#####\n",
    "#    if isCorrect(testDatasetDirectory, z, SVMResults):\n",
    "#        SVMcounter+=1\n",
    "#    if isCorrect(testDatasetDirectory, z, KNNResults):\n",
    "#        KNNcounter+=1 \n",
    "#    if isCorrect(testDatasetDirectory, z, KNN5Results):\n",
    "#        KNN5counter+=1 \n",
    "#     if isCorrect(testDatasetDirectory, z, KMeansResults):\n",
    "#         KMeanscounter+=1\n",
    "#     if isCorrect(testDatasetDirectory, z, RandomForest2Results):\n",
    "#         RandomForest2counter+=1 \n",
    "#     if isCorrect(testDatasetDirectory, z, RandomForest4Results):\n",
    "#         RandomForest4counter+=1     \n",
    "#     if isCorrect(testDatasetDirectory, z, RandomForest6Results):\n",
    "#         RandomForest6counter+=1    \n",
    "#     if isCorrect(testDatasetDirectory, z, RandomForest8Results):\n",
    "#         RandomForest8counter+=1     \n",
    "#     if isCorrect(testDatasetDirectory, z, RandomForest10Results):\n",
    "#         RandomForest10counter+=1            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "387\n"
     ]
    }
   ],
   "source": [
    "# print(SVMcounter)\n",
    "# print(KNNcounter)\n",
    "# print(KNN5counter)\n",
    "# print(KMeanscounter)\n",
    "# print(RandomForest2counter)\n",
    "# print(RandomForest4counter)\n",
    "# print(RandomForest6counter)\n",
    "# print(RandomForest8counter)\n",
    "# print(RandomForest10counter)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
