{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "from sklearn import svm\n",
    "from sklearn import tree\n",
    "from statistics import mode\n",
    "%run Utilities.ipynb\n",
    "%run Preprocessor.ipynb\n",
    "%run LineSegmentor.ipynb\n",
    "%run FeatureExtractor.ipynb\n",
    "%run FeatureExtractor2.ipynb\n",
    "%run Classifiers.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Constants\n",
    "\n",
    "#Path to generate the dataset at\n",
    "testDatasetDirectory = \"Data\\\\data\\\\\"\n",
    "\n",
    "prep = Preprocessor()\n",
    "extractor=LBP_Feature_Extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(x_test)\n",
    "# plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 600/600 [49:17<00:00,  4.93s/it]\n"
     ]
    }
   ],
   "source": [
    "SVMcounter = 0\n",
    "KNNcounter = 0\n",
    "RandomForest8counter = 0\n",
    "NNcounter = 0\n",
    "counter = 0\n",
    "SlantCounter = 0\n",
    "for i in tqdm(range(0,600)):\n",
    "    \n",
    "    ##################################TRAINING############################################################\n",
    "    ######Reading the inputs and labelling the training dataset######\n",
    "    \n",
    "    z = '%02d' % i\n",
    "    #z = '32'\n",
    "    \n",
    "#     if not os.path.exists(testDatasetDirectory+z):\n",
    "#         continue\n",
    "    x_train, y_train, x_test = readTestCase(testDatasetDirectory+z)\n",
    "    x_train_gray = []\n",
    "    x_train_binary = []\n",
    "    x_train_original = []\n",
    "\n",
    "    \n",
    "    #####Preprocessing every image in the input dataset######\n",
    "    for img in x_train:    \n",
    "        gray, binary, original = prep.preprocessing_pipeline_image(img)\n",
    "        x_train_gray.append(gray)\n",
    "        x_train_binary.append(binary)\n",
    "        x_train_original.append(original)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    x_train_segments =  np.empty(256)\n",
    "    y_train_segments = []\n",
    "\n",
    "    for i in range(len(x_train_gray)):\n",
    "        gray_lines, binary_lines, orig_lines = LineSegmentor(x_train_gray[i], x_train_binary[i], x_train_original[i]).segment()\n",
    "        \n",
    "        for j in range(len(binary_lines)):\n",
    "#             if j>4:\n",
    "#                 break\n",
    "            lbpHist = computeLBPHist(binary_lines[j])\n",
    "            x_train_segments = np.vstack((x_train_segments, lbpHist))\n",
    "            \n",
    "            ##Labelling the segmented dataset##\n",
    "            if (i<2):\n",
    "                y_train_segments.append(1)\n",
    "            elif (i<4):\n",
    "                y_train_segments.append(2)\n",
    "            else:\n",
    "                y_train_segments.append(3) \n",
    "    \n",
    "    \n",
    "    y_train_segments = np.asarray(y_train_segments)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    ######################################TEST###################################################### \n",
    "    \n",
    "    #####Preprocessing every image in the testing dataset######\n",
    "    x_test_gray, x_test_binary, x_test_original = prep.preprocessing_pipeline_image(x_test)\n",
    "    \n",
    "    \n",
    "    #####Segmenting the dataset into lines#####\n",
    "    ####And Calculating the features vector####\n",
    "    gray_lines, binary_lines, orig_lines = LineSegmentor(x_test_gray, x_test_binary, x_test_original).segment()\n",
    "    x_test_segments = np.empty([len(binary_lines), 256])\n",
    "    \n",
    "    \n",
    "    for i in range(len(binary_lines)):\n",
    "        lbpHist = computeLBPHist(binary_lines[i])\n",
    "        x_test_segments[i] = lbpHist\n",
    "        \n",
    "       \n",
    "    \n",
    "    \n",
    "    \n",
    "    ####Classifying the test case#####\n",
    "    SVMResults = SVMClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    KNNResults = KNNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments)\n",
    "    RandomForest8Results = RandForestClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, max_depth=8, random_state=0)\n",
    "    \n",
    "\n",
    "    \n",
    "    results = SVMResults\n",
    "    results = np.vstack((results,KNNResults))\n",
    "    results = np.vstack((results,RandomForest8Results))\n",
    "    results = np.sum(results, axis = 0)\n",
    "    \n",
    "    \n",
    "    if results[np.argmax(results)]/(sum(results)*100) < 40:\n",
    "            NNResults = NNClassifier(x_train_segments[1:len(x_train_segments)], y_train_segments, x_test_segments, hidden_layer_sizes = [100, 50],max_iter=400)\n",
    "            results = np.vstack((results,NNResults))\n",
    "            \n",
    "            ##############################################\n",
    "            #print(z)\n",
    "#             x_train_slant =  np.empty(9)\n",
    "#             y_train_slant = []\n",
    "#             for i in range(len(x_train_gray)):\n",
    "#                 gray_lines, binary_lines, orig_lines = LineSegmentor(x_train_gray[i], x_train_binary[i], x_train_original[i]).segment()\n",
    "        \n",
    "#                 for j in range(len(binary_lines)):\n",
    "#                     if j>2:\n",
    "#                         break\n",
    "#                     slantHist = computeSlantHistogram(binary_lines[j])\n",
    "#                     x_train_slant = np.vstack((x_train_slant, slantHist))\n",
    "\n",
    "#                     ##Labelling the segmented dataset##\n",
    "#                     if (i<2):\n",
    "#                         y_train_slant.append(1)\n",
    "#                     elif (i<4):\n",
    "#                         y_train_slant.append(2)\n",
    "#                     else:\n",
    "#                         y_train_slant.append(3) \n",
    "             \n",
    "#             ###TEST####\n",
    "#             gray_lines, binary_lines, orig_lines = LineSegmentor(x_test_gray, x_test_binary, x_test_original).segment()\n",
    "#             x_test_slant = np.empty([len(binary_lines), 9])\n",
    "#             for i in range(len(binary_lines)):\n",
    "#                 slantHist = computeSlantHistogram(binary_lines[i])\n",
    "#                 x_test_slant[i] = slantHist\n",
    "            \n",
    "            \n",
    "#             RandSlantResults = RandForestClassifier(x_train_slant[1:len(x_train_segments)], y_train_slant, x_test_slant, max_depth=8, random_state=0)\n",
    "#             RandSlantResults = np.sum(RandSlantResults, axis = 0)\n",
    "#             #print(KNNSlantResults)\n",
    "#             predictionSlant = np.zeros(1)\n",
    "#             predictionSlant[0] = np.argmax(RandSlantResults) + 1\n",
    "#             if isCorrect(testDatasetDirectory, z, predictionSlant):  \n",
    "#                 SlantCounter += 1\n",
    "                \n",
    "#             results = np.vstack((results,RandSlantResults))   \n",
    "#             ##############################################\n",
    "     \n",
    "    results = np.sum(results, axis = 0)\n",
    "    \n",
    "    \n",
    "    prediction = np.zeros(1)\n",
    "    prediction[0] = np.argmax(results) + 1\n",
    "    \n",
    "    if isCorrect(testDatasetDirectory, z, prediction):  \n",
    "        counter += 1\n",
    "    if(i%100==0):\n",
    "        print(counter)\n",
    "#     else:\n",
    "#         print(results)\n",
    "#         print(z)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "573\n"
     ]
    }
   ],
   "source": [
    "# print(SVMcounter)\n",
    "# print(KNNcounter)\n",
    "# print(KNN5counter)\n",
    "# print(KMeanscounter)\n",
    "# print(RandomForest2counter)\n",
    "# print(RandomForest4counter)\n",
    "# print(RandomForest6counter)\n",
    "# print(RandomForest8counter)\n",
    "# print(RandomForest10counter)\n",
    "# print(SlantCounter)\n",
    "print(counter)\n",
    "# print(NNcounter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
