{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Always make all imports in the first cell of the notebook, run them all once.\n",
    "import cv2\n",
    "import numpy as np\n",
    "import math\n",
    "import glob\n",
    "import skimage\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.filters.rank import otsu\n",
    "from skimage.filters import median, threshold_otsu\n",
    "# import import_ipynb\n",
    "# import Utilities\n",
    "%run Utilities.ipynb\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    @staticmethod\n",
    "    def read_images(fileName, imagesIDs):\n",
    "            #fileName = fileName + '/*png'\n",
    "            x_train = []\n",
    "            x_images_names = []\n",
    "            for imageID in imagesIDs:\n",
    "                img = cv2.imread(filename+'/'+imageID) ## cv2.imread reads images in RGB format\n",
    "                x_images_names.append(imageID)\n",
    "                x_train.append(img)\n",
    "            x_train = np.asarray(x_train)\n",
    "            return x_train, x_images_names\n",
    "\n",
    "    @staticmethod    \n",
    "    def preprocess(img):\n",
    "        # Reduce image noise.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.GaussianBlur(img, (5, 5), 0)\n",
    "\n",
    "\n",
    "        # Binarize the image.\n",
    "        # _,thresholded_img =  cv2.threshold(img, 165,255,cv2.THRESH_BINARY)\n",
    "        _,thresholded_img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "\n",
    "        # Return pre processed images.\n",
    "        return thresholded_img\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def crop(img):\n",
    "        # Converting the image to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        _, binary = cv2.threshold(gray, 225, 255, cv2.THRESH_BINARY_INV)\n",
    "        \n",
    "        \n",
    "        # Finding all contours in the image\n",
    "        contours, hierarchy = cv2.findContours(binary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        \n",
    "        #image = cv2.drawContours(image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "        # Minimum contour width to be considered as the black separator line.\n",
    "        threshold_width = 1000\n",
    "        line_offset = 0\n",
    "        \n",
    "        \n",
    "        # Page paragraph boundaries.\n",
    "        height, width = gray.shape\n",
    "        up, down, left, right = 0, height - 1, 0, width - 1\n",
    "\n",
    "        # Detect the main horizontal black separator lines of the IAM handwriting forms.\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            if w < threshold_width:\n",
    "                continue\n",
    "            if y < height // 2:\n",
    "                up = max(up, y + h + line_offset)\n",
    "            else:\n",
    "                down = min(down, y - line_offset)\n",
    "   \n",
    "        # Applying filters to enhance the image    \n",
    "        kernel = np.ones((3, 3), np.uint8)\n",
    "        eroded_img = cv2.erode(binary, kernel, iterations=2)\n",
    "        # Get horizontal and vertical histograms.\n",
    "        hor_hist = np.sum(eroded_img, axis=1) / 255\n",
    "        ver_hist = np.sum(eroded_img, axis=0) / 255\n",
    "\n",
    "        # Detect paragraph white padding.\n",
    "        while left < right and ver_hist[left] == 0:\n",
    "            left += 1\n",
    "        while right > left and ver_hist[right] == 0:\n",
    "            right -= 1\n",
    "        while up < down and hor_hist[up] == 0:\n",
    "            up += 1\n",
    "        while down > up and hor_hist[down] == 0:\n",
    "            down -= 1\n",
    "            \n",
    "        gray = gray[up:down + 1, left:right + 1]\n",
    "        binary = binary[up:down + 1, left:right + 1]\n",
    "        \n",
    "        return gray, binary\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def save_preprocessed(fileName, x_images_names, x_train_gray,x_train_binary):\n",
    "        if not os.path.exists(fileName +'gray/'):\n",
    "            os.makedirs(fileName +'gray/')\n",
    "        if not os.path.exists(fileName +'binary/'):\n",
    "            os.makedirs(fileName +'binary/')    \n",
    "        for i in range(len(x_train_gray)):\n",
    "#             print(fileName +'gray/' + str(x_images_names[i]))\n",
    "#             print(fileName + 'binary/' + str(x_images_names[i]))\n",
    "            cv2.imwrite(fileName +'gray/' + str(x_images_names[i]) ,x_train_gray[i])\n",
    "            cv2.imwrite(fileName + 'binary/' + str(x_images_names[i]),x_train_binary[i])\n",
    "    \n",
    "    @staticmethod\n",
    "    def preprocessing_pipeline(fileName, imagesIDs):\n",
    "        x_train, x_images_names = Preprocessor.read_images(fileName, imagesIDs)\n",
    "        x_train_gray = []\n",
    "        x_train_binary = []\n",
    "        for img in x_train:\n",
    "            preprocessedImage = Preprocessor.preprocess(img)\n",
    "            croppedImageGray, croppedImageBinary = Preprocessor.crop(preprocessedImage)\n",
    "            x_train_gray.append(croppedImageGray)\n",
    "            x_train_binary.append(croppedImageBinary)\n",
    "        \n",
    "        \n",
    "        Preprocessor.save_preprocessed(fileName, x_images_names, x_train_gray, x_train_binary)\n",
    "        return x_train_gray, x_train_binary \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prep = Preprocessor()\n",
    "# writerImagesID = []\n",
    "# x_train_gray, x_train_binary = prep.preprocessing_pipeline('data/imagesTest')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2125, 2383)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-ee1ed566821e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;31m#     plt.show()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mgray_lines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbin_lines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLineSegmentor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbinary_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msegment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m     \u001b[0mx_segmented\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_lines\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-6a83b3d18b81>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, gray_img, bin_img)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;31m# Calculate peaks and valleys of the page.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_peaks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mavg_peaks_dist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpeaks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetect_valleys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-106-6a83b3d18b81>\u001b[0m in \u001b[0;36mdetect_peaks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     73\u001b[0m             \u001b[1;31m# If the black pixels density of the row is below than threshold\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m             \u001b[1;31m# then continue to the next row.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 75\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhor_hist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mthreshold_high\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     76\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "gray_img = x_train_gray[25]\n",
    "bin_img = x_train_binary[25]\n",
    "\n",
    "print(gray_img.shape)\n",
    "grayFiles = 'data/imagesTestGray/*png'\n",
    "binaryFiles = 'data/imagesTestBinary/*png'\n",
    "gray_images = []\n",
    "binary_images = []\n",
    "x_segmented = []\n",
    "for img in glob.glob(grayFiles):\n",
    "    grayTemp = cv2.imread(img)\n",
    "    grayTemp = cv2.cvtColor(grayTemp, cv2.COLOR_RGB2GRAY)    \n",
    "    gray_images.append(grayTemp)\n",
    "\n",
    "for img in glob.glob(binaryFiles):\n",
    "    binaryTemp = cv2.imread(img)\n",
    "    _, binaryTemp = cv2.threshold(binaryTemp, 225, 255, cv2.THRESH_BINARY)\n",
    "    binary_images.append(binaryTemp)    \n",
    "\n",
    "    \n",
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(gray_images[0])\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# gray_images = np.asarray(gray_images)\n",
    "# binary_images = np.asarray(binary_images)\n",
    "# print(gray_images.shape)\n",
    "# print(binary_images.shape)\n",
    "# gray_img = gray_images[0]\n",
    "# bin_img = binary_images[0]\n",
    "#print(gray_img.shape)\n",
    "for i in range(len(gray_images)-70):\n",
    "#     fig = plt.figure(figsize=(15,15))\n",
    "#     plt.imshow(binary_images[i])\n",
    "#     plt.show()\n",
    "\n",
    "    gray_lines, bin_lines = LineSegmentor(gray_images[i], binary_images[i]).segment()\n",
    "    x_segmented.append(gray_lines)\n",
    "    \n",
    "    \n",
    "x_segmented = np.asarray(x_segmented)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img = x_train[0]\n",
    "# x=408\n",
    "# y=746\n",
    "# w=1661\n",
    "# h=89\n",
    "# cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "# fig = plt.figure(figsize=(15,15))\n",
    "# plt.imshow(img)\n",
    "# # show_images(x_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
